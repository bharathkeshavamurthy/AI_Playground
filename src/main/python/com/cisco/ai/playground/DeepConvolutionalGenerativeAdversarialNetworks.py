# This entity encapsulates a Deep Convolutional Generative Adversarial Network (DCGANs)
# Author: Bharath Keshavamurthy
# Organization: CISCO Systems
# Copyright (c) 2019. All Rights Reserved.

import IPython
import tensorflow
import matplotlib.pyplot as plt

tensorflow.enable_eager_execution()


# This class makes use of the Handwriting dataset from MNIST
# The Generator generates samples of digits (0-9)
# The Discriminator then classifies inputs as real (handwritten) or fake (generated by the generator)
class DeepConvolutionalGenerativeAdversarialNetworks(object):
    # Number of epochs to train
    NUM_OF_EPOCHS = 50

    # The initialization sequence
    def __init__(self):
        print('[INFO] DeepConvolutionalGenerativeAdversarialNetworks Initialization: Bringing things up...')
        (self.training_data, self.training_labels), (_, _) = tensorflow.keras.datasets.mnist.load_data()
        self.training_data = self.training_data.reshape(self.training_data.shape[0], 28, 28, 1).astype('float32')
        self.training_data = (self.training_data - 127.5) / 127.5
        self.training_data_set = tensorflow.data.Dataset.from_tensor_slices(self.training_data).shuffle(60000). \
            batch(256)
        self.generator_model = self.build_generator_model()
        self.discriminator_model = self.build_discriminator_model()
        self.generator_optimizer = tensorflow.train.AdamOptimizer(1e-4)
        self.discriminator_optimizer = tensorflow.train.AdamOptimizer(1e-4)

    # Build and Return the Generator
    @staticmethod
    def build_generator_model():
        generator_model = tensorflow.keras.Sequential(
            [tensorflow.keras.layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)),
             tensorflow.keras.layers.BatchNormalization(),
             tensorflow.keras.layers.LeakyReLU(),
             tensorflow.keras.layers.Reshape((7, 7, 256)),
             tensorflow.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1),
                                                     padding='same', use_bias=False),
             tensorflow.keras.layers.BatchNormalization(),
             tensorflow.keras.layers.LeakyReLU(),
             tensorflow.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), use_bias=False, padding='same'),
             tensorflow.keras.layers.BatchNormalization(),
             tensorflow.keras.layers.LeakyReLU(),
             tensorflow.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), use_bias=False, padding='same',
                                                     activation='tanh')])
        return generator_model

    # Build and Return the Discriminator
    @staticmethod
    def build_discriminator_model():
        discriminator_model = tensorflow.keras.Sequential(
            [tensorflow.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),
             tensorflow.keras.layers.LeakyReLU(),
             tensorflow.keras.layers.Dropout(0.3),
             tensorflow.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),
             tensorflow.keras.layers.LeakyReLU(),
             tensorflow.keras.layers.Dropout(0.3),
             tensorflow.keras.layers.Flatten(),
             tensorflow.keras.layers.Dense(1)]
        )
        return discriminator_model

    # Setup the loss function and the optimizers for both the generator and the discriminator
    @staticmethod
    def setup(real_output, generated_output):
        generator_loss = tensorflow.losses.sigmoid_cross_entropy(tensorflow.ones_like(generated_output),
                                                                 generated_output)
        discriminator_loss_real = tensorflow.losses.sigmoid_cross_entropy(
            multi_class_labels=tensorflow.ones_like(real_output), logits=real_output)
        discriminator_loss_fake = tensorflow.losses.sigmoid_cross_entropy(
            multi_class_labels=tensorflow.ones_like(generated_output), logits=generated_output)
        discriminator_loss = discriminator_loss_real + discriminator_loss_fake
        return generator_loss, discriminator_loss

    # Evaluate the losses and the gradients, and then apply the optimization procedure
    def training_step(self, images):
        noise = tensorflow.random_normal([256, 100])
        with tensorflow.GradientTape() as generator_gradient, tensorflow.GradientTape() as discriminator_gradient:
            discriminator_output_real = self.discriminator_model(images, training=True)
            generator_output = self.generator_model(noise, training=True)
            discriminator_output_fake = self.discriminator_model(generator_output, training=True)
            generator_loss, discriminator_loss = self.setup(discriminator_output_real, discriminator_output_fake)
        gradients_of_generator = generator_gradient.gradient(generator_loss,
                                                             self.generator_model.variables)
        gradients_of_discriminator = discriminator_gradient.gradient(discriminator_loss,
                                                                     self.discriminator_model.variables)
        self.generator_optimizer.apply_gradients(zip(gradients_of_generator,
                                                     self.generator_model.variables))
        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,
                                                         self.discriminator_model.variables))

    # Generate and Save Images
    def generate_and_save(self, random_input):
        predictions = self.generator_model(random_input, training=False)
        fig = plt.figure(figsize=(4, 4))
        for i in range(predictions.shape[0]):
            plt.subplot(4, 4, i + 1)
            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
            plt.axis('off')
        plt.show()

    # High-level training call
    def train(self):
        random_vector_for_generation = tensorflow.random_normal([16, 100])
        train_step = tensorflow.contrib.eager.defun(self.training_step)
        for epoch in range(0, self.NUM_OF_EPOCHS):
            for images in self.training_data_set:
                train_step(images)
            IPython.display.clear_output(wait=True)
            self.generate_and_save(random_vector_for_generation)
        IPython.display.clear_output(wait=True)
        self.generate_and_save(random_vector_for_generation)

    # The termination sequence
    def __exit__(self, exc_type, exc_val, exc_tb):
        print('[INFO] DeepConvolutionalGenerativeAdversarialNetworks Termination: Tearing things down...')


# Run Trigger
if __name__ == '__main__':
    print('[INFO] DeepConvolutionalGenerativeAdversarialNetworks Trigger: Starting system assessment!')
    DCGAN = DeepConvolutionalGenerativeAdversarialNetworks()
    DCGAN.train()
